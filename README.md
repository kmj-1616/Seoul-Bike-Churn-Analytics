# Seoul-Bike-Churn-Analytics
2025 바이브코딩 워크숍

## 개요
이 프로젝트는 취업을 위해서 만든 학습용 프로젝트입니다.
목표로 하는 포지션(Job Desription)은 다음과 같습니다.
https://hanssem.applyin.co.kr/jobs/17808
https://www.wanted.co.kr/wd/277851 
https://www.wanted.co.kr/wd/277505
https://toss.im/career/job-detail?job_id=4071102003&company=%ED%86%A0%EC%8A%A4&detailedPosition=%EA%B3%B5%ED%86%B5

기획은 ChatGPT와 Grok3를 사용하였고, 구현은 Cusor를 이용한 바이브 코딩으로 구현하였습니다.

## 프로젝트 상세

### 공공자전거 이탈 분석 프로젝트 🚲  
**목표**: 서울시 따릉이 데이터를 활용하여 사용자 이탈 원인을 분석하고 유지 전략 제시  
- 서울열린데이터광장 API를 활용하여 월간 이용 데이터를 수집 및 전처리  
- SQL(BigQuery)로 연령대/이용 시간대별 분석 수행  
- Python으로 사용자 군집화(K-Means), 휴면 사용자 패턴 분석  
- 가상의 A/B 테스트를 설계하여 리텐션 향상 전략 제안  

→ **사용 기술**: SQL, Python, GCP, A/B Testing, 시각화  

# 제품 요구사항 문서: 공공자전거 이탈 분석 프로젝트

## 프로젝트 개요
공공자전거 이탈 분석 프로젝트는 서울열린데이터광장의 따릉이 데이터를 활용하여 사용자 이탈 원인을 분석하고, 데이터 기반의 사용자 유지 전략을 제안합니다. SQL(BigQuery), Python, Google Cloud Platform(GCP), A/B 테스트, 시각화 도구를 사용해 이탈 패턴을 파악하고 실행 가능한 인사이트를 도출합니다. 본 프로젝트는 사용자 세분화와 유지율 향상에 초점을 맞추며, 핀테크 및 데이터 분석 직무 지원을 위한 포트폴리오로 활용됩니다.

## 목표
- **주요 목표**: 따릉이 시스템의 사용자 이탈 요인을 파악하고, 이탈률을 10% 감소시킬 수 있는 유지 전략 제안.
- **부차적 목표**:
  - 사용자 활동 데이터를 기반으로 활성 및 이탈 위험 사용자를 세분화.
  - 유지 전략 효과를 검증하기 위한 가상의 A/B 테스트 설계.
  - 이해관계자에게 분석 결과를 효과적으로 전달할 수 있는 시각화 자료 생성.

## 사용자 스토리
- **데이터 분석가**로서, **따릉이 이용 데이터를 수집 및 전처리**하고 싶습니다, 이를 통해 **정확한 분석을 위한 데이터 품질을 보장**할 수 있습니다.
- **데이터 분석가**로서, **연령대 및 이용 시간대별 사용 패턴을 분석**하고 싶습니다, 이를 통해 **이탈과 관련된 인구통계 및 행동 요인을 파악**할 수 있습니다.
- **데이터 분석가**로서, **사용자 활동 기반으로 군집화**하고 싶습니다, 이를 통해 **이탈 위험 사용자를 타겟팅한 맞춤형 전략을 개발**할 수 있습니다.
- **프로덕트 매니저**로서, **유지 전략 제안 보고서**를 받고 싶습니다, 이를 통해 **사용자 유지율을 높이는 조치를 실행**할 수 있습니다.
- **이해관계자**로서, **시각화된 분석 결과**를 보고 싶습니다, 이를 통해 **이탈 원인과 제안된 솔루션을 명확히 이해**할 수 있습니다.

## 기능 요구사항

### 데이터 수집 및 전처리
- **FR1**: 서울열린데이터광장 API를 연동하여 따릉이 월간 이용 데이터(예: 이용 시간, 연령대, 대여/반납 정거장)를 수집.
- **FR2**: Python(Pandas)을 사용해 결측값, 이상치, 중복 데이터를 전처리.
- **FR3**: 정제된 데이터를 Google BigQuery에 저장하여 효율적인 쿼리 실행 가능.

### 데이터 분석
- **FR4**: SQL(BigQuery)을 활용해 연령대 및 시간대별 이용 패턴 분석.
- **FR5**: Python(Scikit-learn)으로 K-Means 군집화를 구현해 사용자를 활성, 간헐적, 이탈 위험 그룹으로 세분화.
- **FR6**: Python을 사용해 이탈 패턴(예: 30일 이상 미사용 사용자) 식별.

### 전략 개발
- **FR7**: 유지 전략 효과 검증을 위한 가상의 A/B 테스트 설계(예: 할인 알림 vs. 무알림).
- **FR8**: 분석 결과를 바탕으로 최소 3개의 유지 전략 제안(예: 타겟 프로모션, 앱 UX 개선).

### 시각화 및 보고서
- **FR9**: Python(Matplotlib, Seaborn) 또는 GCP Data Studio를 사용해 이탈률, 군집 프로필 등 시각화 생성.
- **FR10**: 분석 결과, 전략, 시각화를 포함한 이해관계자向け 최종 보고서 작성.

## 비기능 요구사항
- **NFR1**: 데이터 처리 스크립트는 최대 100만 레코드 데이터셋에 대해 10분 이내 실행 완료.
- **NFR2**: 시각화 자료는 PNG/PDF 형식으로 내보내기 가능해야 함.
- **NFR3**: 코드는 문서화되어 GitHub 공개 리포지토리(`Seoul-Bike-Churn-Analytics`)에 MIT License로 호스팅.
- **NFR4**: 분석은 서울열린데이터광장의 데이터 이용 약관을 준수해야 함.
- **NFR5**: 프로젝트는 주 10시간 기준 6주 내 완료.

## 제외 항목
- 실시간 데이터 스트리밍 또는 실시간 대시보드 구현.
- 따릉이 내부 시스템 또는 사용자 데이터베이스와의 통합.
- 제안된 유지 전략의 실제 프로덕션 환경 적용.
- K-Means 군집화 외의 고급 머신러닝 모델 개발.

## 가정
- 서울열린데이터광장 API가 이탈 분석에 필요한 데이터(연령, 이용 내역 등)를 제공.
- 공개 데이터는 사용자 동의 없이 분석 가능.
- GCP 무료 티어로 BigQuery 및 Data Studio 사용 가능.

## 의존성
- 서울열린데이터광장 API 키.
- Python 라이브러리: Pandas, Scikit-learn, Matplotlib, Seaborn, Google Cloud SDK.
- BigQuery 및 Data Studio가 활성화된 Google Cloud Platform 계정.

## 성공 지표
- **정량적**:
  - 통계적으로 유의미한 이탈 요인 최소 3개 식별.
  - K-Means 군집화의 실루엣 점수 기준 80% 이상 세분화 정확도 달성.
  - 시뮬레이션에서 이탈률 10% 감소 예상되는 전략 제안.
- **정성적**:
  - 이해관계자의 보고서 명확성 및 시각화 효과에 대한 긍정적 피드백.
  - 동료 리뷰를 통한 코드 가독성 및 문서화 품질 인정.



